{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15353b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('./rtaUtils')\n",
    "import wandb, os\n",
    "from wandb.keras import WandbCallback\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "from rtaUtils import paths, experiment, data_loading, data_preparation\n",
    "\n",
    "# Disable GPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)\n",
    "for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57366f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features ##################################################################\n",
    "numeric_feat   = ['latitude', 'longitude', 'altitude'] # 'vspeed', 'speed', 'track', 'hav_distance'\n",
    "categoric_feat = [] #'operator'      \n",
    "objective      = ['latitude', 'longitude', 'altitude']\n",
    "\n",
    "feat_dict = dict(\n",
    "    numeric=numeric_feat,\n",
    "    categoric=categoric_feat,\n",
    "    objective=objective\n",
    ")\n",
    "\n",
    "### Experiment setup ##########################################################\n",
    "model_type   = 'LSTM'\n",
    "months       = '*' # 20220[12] , 202209\n",
    "airport      = '*'\n",
    "glob_text    = f'{months}-{airport}'\n",
    "\n",
    "# Configuración de los datos y el entrenamiento\n",
    "lookback     = 16\n",
    "lookforward  = 5\n",
    "sampling     = 15\n",
    "epochs       = 15\n",
    "from_parquet = True # Cargar desde parquet, o los tf.data.Datasets\n",
    "\n",
    "\n",
    "# Se definen todos los hiperparámetros del modelo, que se pasan a la clase Experiment\n",
    "# como un diccionario (para no andar con los kwargs). El diccionario se procesa en el\n",
    "# constructor.\n",
    "n_units      = 10\n",
    "act_function = 'tanh'\n",
    "batch_size   = 128\n",
    "\n",
    "model_config = dict(\n",
    "    n_units=n_units,\n",
    "    act_function=act_function,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4082549",
   "metadata": {},
   "source": [
    "# Configuración para Weights and Biases\n",
    "dt = datetime.datetime.now().strftime('%m%d_%H%M')\n",
    "\n",
    "wandb_config = {\n",
    "    'batch_size' : batch_size,\n",
    "    'lookback' : lookback,\n",
    "    'n_units' : n_units,\n",
    "    'sampling' : sampling,\n",
    "    'model_type' : model_type\n",
    "}\n",
    "wandb.init(project='RTAs', config=wandb_config,\n",
    "           name=f'{model_type}_s{sampling}_lb{lookback}_u{n_units}_{dt}'           \n",
    "           # resume='must', id=''\n",
    "          ) \n",
    "wandCallback = WandbCallback(save_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4f422",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9107369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10)                560       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                165       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 5, 3)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 725\n",
      "Trainable params: 725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instanciación de Experiment\n",
    "experimento = experiment.ExperimentTrajectory(\n",
    "    lookback=lookback,\n",
    "    lookforward=lookforward,\n",
    "    sampling=sampling,\n",
    "    model_config=model_config,\n",
    "    months=months, \n",
    "    airport=airport,\n",
    "    features=feat_dict\n",
    ")\n",
    "experimento.init_model()\n",
    "# Si ya se ha entrenado antes, load_model() carga el último modelo\n",
    "# experimento.load_model()\n",
    "\n",
    "experimento.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f5190e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jorge\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Epoch 1/15\n",
      "4093/4093 [==============================] - 84s 20ms/step - loss: 0.0182 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 1.2498e-04\n",
      "Epoch 2/15\n",
      "4093/4093 [==============================] - 107s 25ms/step - loss: 0.0036 - mean_squared_error: 7.4005e-05 - val_loss: 0.0033 - val_mean_squared_error: 6.2765e-05\n",
      "Epoch 3/15\n",
      "4093/4093 [==============================] - 103s 24ms/step - loss: 0.0030 - mean_squared_error: 5.5303e-05 - val_loss: 0.0031 - val_mean_squared_error: 5.6436e-05\n",
      "Epoch 4/15\n",
      "4093/4093 [==============================] - 87s 20ms/step - loss: 0.0027 - mean_squared_error: 4.8377e-05 - val_loss: 0.0030 - val_mean_squared_error: 4.9086e-05\n",
      "Epoch 5/15\n",
      "4093/4093 [==============================] - 72s 17ms/step - loss: 0.0025 - mean_squared_error: 4.4300e-05 - val_loss: 0.0027 - val_mean_squared_error: 4.4799e-05\n",
      "Epoch 6/15\n",
      "4093/4093 [==============================] - 72s 17ms/step - loss: 0.0024 - mean_squared_error: 4.2071e-05 - val_loss: 0.0028 - val_mean_squared_error: 4.4928e-05\n",
      "Epoch 7/15\n",
      "4093/4093 [==============================] - 69s 16ms/step - loss: 0.0023 - mean_squared_error: 4.0616e-05 - val_loss: 0.0023 - val_mean_squared_error: 4.1422e-05\n",
      "Epoch 8/15\n",
      "4093/4093 [==============================] - 92s 22ms/step - loss: 0.0023 - mean_squared_error: 3.9400e-05 - val_loss: 0.0028 - val_mean_squared_error: 4.2221e-05\n",
      "Epoch 9/15\n",
      "4093/4093 [==============================] - 86s 20ms/step - loss: 0.0022 - mean_squared_error: 3.8343e-05 - val_loss: 0.0024 - val_mean_squared_error: 3.9516e-05\n",
      "Epoch 10/15\n",
      "4093/4093 [==============================] - 78s 18ms/step - loss: 0.0022 - mean_squared_error: 3.7349e-05 - val_loss: 0.0025 - val_mean_squared_error: 3.8651e-05\n",
      "Epoch 11/15\n",
      "4093/4093 [==============================] - 73s 17ms/step - loss: 0.0022 - mean_squared_error: 3.6417e-05 - val_loss: 0.0026 - val_mean_squared_error: 4.0043e-05\n",
      "Epoch 12/15\n",
      "4093/4093 [==============================] - 68s 16ms/step - loss: 0.0021 - mean_squared_error: 3.5539e-05 - val_loss: 0.0021 - val_mean_squared_error: 3.6464e-05\n",
      "Epoch 13/15\n",
      "4093/4093 [==============================] - 75s 18ms/step - loss: 0.0021 - mean_squared_error: 3.4733e-05 - val_loss: 0.0022 - val_mean_squared_error: 3.5993e-05\n",
      "Epoch 14/15\n",
      "4093/4093 [==============================] - 76s 18ms/step - loss: 0.0020 - mean_squared_error: 3.4140e-05 - val_loss: 0.0021 - val_mean_squared_error: 3.5017e-05\n",
      "Epoch 15/15\n",
      "4093/4093 [==============================] - 70s 17ms/step - loss: 0.0020 - mean_squared_error: 3.3530e-05 - val_loss: 0.0019 - val_mean_squared_error: 3.4162e-05\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "history = experimento.train(epochs=epochs, from_parquet=from_parquet, add_callbacks=[]) \n",
    "# add_callbacks = [wandCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba50c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = pd.read_csv(experimento.model_path_log)\n",
    "skip = 0\n",
    "\n",
    "plt.plot([str(x) for x in range(1+skip,progress.shape[0]+1)], progress['loss'].iloc[skip:], label='loss')\n",
    "plt.plot([str(x) for x in range(1+skip,progress.shape[0]+1)], progress['val_loss'].iloc[skip:], label='validation loss')\n",
    "plt.title(f'{model_type}.u{n_units}lb{lookback}s{sampling}')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "if progress.shape[0]>10:\n",
    "    plt.xticks([str(x) for x in range(1+skip,progress.shape[0],progress.shape[0]//5)])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e5b22",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo\n",
    "experimento.load_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d252d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# experimento.evaluate() evalúa el modelo sobre los conjuntos de validación y test\n",
    "# Para deshabilitar la impresión por pantalla, cambiar a print_err=False \n",
    "experimento.evaluate(from_parquet=from_parquet, print_err=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9af4b93",
   "metadata": {},
   "source": [
    "# Evaluación del modelo a cierto tiempo del aeropuerto\n",
    "experimento.evaluate_at_times()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5928745",
   "metadata": {},
   "source": [
    "# Evaluación de cada aeropuerto de origen por separado\n",
    "experimento.evaluate_airports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917778f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimento.get_evaluation_results() extrae un dataframe con los resultados calculados \n",
    "experimento.get_evaluation_results('long')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85f199",
   "metadata": {},
   "source": [
    "## Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a CSV\n",
    "experimento.get_evaluation_results('wide')\\\n",
    "           .to_csv(f'./results/{model_type}_s{sampling}_lb{lookback}_lf{lookforward}_u{n_units}.csv', \n",
    "                 header=True,index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7bfbb",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loading.load_final_data('202201','test',sampling=15).sort_values(['fpId','timestamp'])\n",
    "trajectories = (data.groupby(['fpId','aerodromeOfDeparture']).count().vectorId.reset_index()\n",
    "                    .sort_values(['aerodromeOfDeparture', 'vectorId']))\n",
    "trajectories[trajectories.aerodromeOfDeparture == 'LEBL'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos una o más trayectorias\n",
    "fpId_trajectory = ['AT05788200',] #'AT05486226'\n",
    "data = data[data.fpId.isin(fpId_trajectory)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de las ventanas de las trayectorias\n",
    "windows = data_preparation.get_windows(data, lookback, experimento.encoders, experimento.scaler, features = feat_dict)\n",
    "windows = experimento._format_data(windows)\n",
    "\n",
    "predictions = experimento.model.predict(windows.batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75debd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = data[['latitude','longitude','altitude']].copy()\n",
    "# Desescalamos los datos\n",
    "pred_unsc = experimento.scaler.inverse_transform(\n",
    "    np.concatenate([np.zeros((predictions.shape[0],len(numeric_feat))),\n",
    "                    predictions.reshape((predictions.shape[0],len(objective)))],axis=1)\n",
    "    )[:,-len(objective):]\n",
    "# Unimos las predicciones con los valores reales para representarlas en el mapa\n",
    "df_viz = pd.concat([df_viz, pd.DataFrame(pred_unsc, columns=df_viz.columns)], axis=0)\n",
    "df_viz['real'] = 'real'\n",
    "df_viz.iloc[-len(predictions):,-1] = 'predicho'\n",
    "\n",
    "# Asignamos a cada predicción el mismo valor en la columna \"index\" que el del\n",
    "# último vector de la ventana que la originó (para alinearlos en los perfiles\n",
    "# de altitud, longitud y latitud)\n",
    "# Ojo: si la trayectoria está \"a trozos\", casca\n",
    "df_viz = df_viz.reset_index()\n",
    "df_viz.iloc[-pred_unsc.shape[0]:,0] = df_viz.iloc[lookback-1:-pred_unsc.shape[0],0].values\n",
    "\n",
    "df_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945685c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_mapbox(df_viz, 'latitude', 'longitude', zoom=6.5,width=900, height=500,\n",
    "                  mapbox_style=\"open-street-map\", opacity = 1,\n",
    "                  color ='real'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_viz, x = 'index', y='altitude', width=600, height=400,\n",
    "                  opacity = 1, color ='real', title='Altitud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8aa40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_viz, x = 'index', y='longitude', width=600, height=400,\n",
    "                  opacity = 1, color ='real', title='Longitud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2182cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_viz, x = 'index', y='latitude', width=600, height=400,\n",
    "                  opacity = 1, color ='real', title='Latitud')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
